{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from utils import *\n",
    "from models.TSSCD import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = device_on()\n",
    "configs, configs_opt_only = Configs(), Configs(is_opt_only=True)\n",
    "plt.rcParams['font.family'] = ['Arial']\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = np.load('models/model_data/dataset/1027/tralid.npy')\n",
    "ds_test = np.load('models/model_data/dataset/1027/test.npy')\n",
    "# print(ds.shape, ds_test.shape)\n",
    "# print(np.vstack((ds, ds_test)).shape)\n",
    "# print(ds[114, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# province, lat_lon = 'ZJ', [121.6767133, 30.0035682]   # for Example Herbicide\n",
    "\n",
    "# province, lat_lon = 'ZJ', [121.24376, 30.37094]   # for Example\n",
    "# province, lat_lon = 'ZJ', [121.24402, 30.37025]\n",
    "\n",
    "# province, lat_lon = 'FJ', [118.6420, 24.8197] # for Example\n",
    "\n",
    "\n",
    "# FOR Grad-CAM\n",
    "# province, lat_lon = 'ZJ', [121.59895, 29.19954]   # 浙江 三门湾 a\n",
    "province, lat_lon = 'ZJ', [121.57974, 29.20018]   # 浙江 三门湾 b\n",
    "# province, lat_lon = 'ZJ', [121.58163, 29.20947]   # 浙江 三门湾 b\n",
    "# province, lat_lon = 'SD', [119.26704, 37.85246]   # 山东 黄河口\n",
    "# province, lat_lon = 'SD', [118.95676, 37.33134]   # 山东 莱州湾\n",
    "# province, lat_lon = 'JS', [120.48908, 33.83914]   # 江苏 射阳河\n",
    "\n",
    "# province, lat_lon = 'SD', [119.27708, 37.83805]       # 山东 东北方位的二次清除\n",
    "# province, lat_lon = 'SD', [119.26807, 37.85097]\n",
    "# province, lat_lon = 'SD', [119.26738, 37.84697]         # wrong\n",
    "# province, lat_lon = 'SD', [119.26875, 37.85408]       # wrong\n",
    "# province, lat_lon = 'SD', [119.28022, 37.83708]         # wrong\n",
    "# province, lat_lon = 'SD', [119.28511, 37.84067]             # wrong\n",
    "# province, lat_lon = 'SD', [119.28358, 37.83966]\n",
    "# province, lat_lon = 'SD', [119.28579, 37.84093]\n",
    "# province, lat_lon = 'SD', [119.26673, 37.85424]     # 模型关注长时特征的例子\n",
    "# province, lat_lon = 'SD', [119.26106, 37.82065]       # Transformer did well\n",
    "# province, lat_lon = 'SD', [119.24424, 37.83787]\n",
    "# province, lat_lon = 'SD', [119.26655, 37.82404]\n",
    "# province, lat_lon = 'SD', [119.2275, 37.83679]\n",
    "# province, lat_lon = 'SD', [119.28157, 37.76546]\n",
    "\n",
    "# province, lat_lon = 'ZJ', [121.57029, 29.20796]\n",
    "# province, lat_lon = 'ZJ', [121.60579, 29.18169]\n",
    "\n",
    "# province, lat_lon = 'JS', [120.48597, 33.84074]       # 射阳河北 化学清除\n",
    "# province, lat_lon = 'JS', [120.47241, 33.85913]\n",
    "# province, lat_lon = 'JS', [120.70254, 33.44989]\n",
    "\n",
    "# province, lat_lon = 'FJ', [119.853361, 26.847862] # 盐田 红树林\n",
    "# province, lat_lon = 'FJ', [119.66703, 26.39474]\n",
    "# province, lat_lon = 'FJ', [119.66703, 26.39498]\n",
    "# province, lat_lon = 'FJ', [119.60481, 26.601]\n",
    "# province, lat_lon = 'FJ', [119.60972, 26.64243]\n",
    "# province, lat_lon = 'FJ', [119.61069, 26.64211]\n",
    "# province, lat_lon = 'FJ', [119.63967, 26.70514]\n",
    "# province, lat_lon = 'FJ', [119.64482, 26.70395]\n",
    "# province, lat_lon = 'FJ', [119.66368, 26.68016]\n",
    "# province, lat_lon = 'FJ', [119.66355, 26.6797]\n",
    "# province, lat_lon = 'FJ', [119.67715, 26.6746]\n",
    "# province, lat_lon = 'FJ', [117.92173, 24.45017]\n",
    "\n",
    "# province, lat_lon = 'SD', [117.60098, 38.76842]\n",
    "# province, lat_lon = 'JS', [120.65606, 33.50901]\n",
    "# province, lat_lon = 'SH', [121.97624, 31.01365]\n",
    "# province, lat_lon = 'GDGX', [109.65412, 21.58811]\n",
    "\n",
    "# TSSCD_FCN, TSSCD_Unet, TSSCD_TransEncoder\n",
    "radius, model_name = 500, 'TSSCD_FCN'\n",
    "model_idx, is_opt_only = '1035', False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, models_opt_only = generate_model_instances(configs), \\\n",
    "                          generate_model_instances(configs_opt_only)\n",
    "                          \n",
    "models, models_opt_only = {model_name: model for model_name, model in models}, \\\n",
    "                          {model_name: model for model_name, model in models_opt_only}\n",
    "                           \n",
    "model_names = models.keys()\n",
    "\n",
    "model_idx, is_opt_only = '1027', True\n",
    "print(f'================== is_opt_only: {is_opt_only} ==================')\n",
    "model = models_opt_only[model_name] if is_opt_only else models[model_name]\n",
    "model_idx = model_idx + ('_opt_only' if is_opt_only else '')\n",
    "\n",
    "model_state_dict = torch.load(os.path.join('models\\\\model_data', model_name, model_idx, f'{model_idx}.pth'), map_location='cuda', weights_only=True)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join('.\\\\TimeSeriesImages\\\\SA_blocks_clipped&mosaic', province)\n",
    "if not os.path.exists(directory):\n",
    "    directory = os.path.join('I:\\\\全国互花米草影像', province)\n",
    "print(f'Using directory: {directory}')\n",
    "\n",
    "dates = pd.date_range(start='2020-01-01', end='2024-12-01', freq='MS') # Dates\n",
    "imgs = [os.path.join(directory, date.strftime('%Y_%m.tif')) for date in dates] # Time Series Images\n",
    "\n",
    "lc_clrmap = {\n",
    "    0: ['#3ABF99', 'S. alterniflora'],       # Spartina alterniflora\n",
    "    1: ['#808080', 'Tidal flats'],       # bare flats\n",
    "    2: ['#069DFF', 'Open water'],       # water\n",
    "    3: ['#6D65A3', 'Herbicide-treated litter'],       # herbicide\n",
    "    4: [\"#F12E2E\", 'other vegetation']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "bands_label = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12', 'VV', 'VH']\n",
    "\n",
    "pixel_ts_values = [extract_time_series_data(lat_lon, img) for img in imgs]\n",
    "pixel_ts_values = np.stack(pixel_ts_values, axis=1) # 12 × 60     \n",
    "model_input = np.expand_dims(pixel_ts_values, axis=0) # 1 × 12 × 60\n",
    "\n",
    "def interpolate_1d(arr):\n",
    "    return pd.Series(arr).interpolate(method='linear', limit_direction='both').values\n",
    "model_input = np.apply_along_axis(interpolate_1d, axis=2, arr=model_input)\n",
    "\n",
    "model_input_4_plot = np.apply_along_axis(interpolate_1d, axis=1, arr=pixel_ts_values)\n",
    "# standardization\n",
    "# print(f'before standardization:\\n{model_input}')\n",
    "model_input, infos = standarlization(model_input)\n",
    "model_input = model_input[:, :-2, :]\n",
    "# print(f'after standardization:\\n{model_input}')\n",
    "# ==================================================================\n",
    "model_input = torch.Tensor(model_input).to(device)\n",
    "preds = model(model_input)\n",
    "\n",
    "class_probs = F.softmax(preds, dim=1)[0].cpu().detach().numpy()\n",
    "preds = torch.argmax(input=preds, dim=1).cpu().numpy()\n",
    "org_output = preds\n",
    "\n",
    "print(f'before filter:\\n{preds[0]}')\n",
    "preds = MajorityFilter(preds, kernel_size=3)[0]  # temporal filter\n",
    "print(f'after filter:\\n{preds}\\n')\n",
    "ndvi = (pixel_ts_values[6, :] - pixel_ts_values[2, :]) / (pixel_ts_values[6, :] + pixel_ts_values[2, :] + 1e-6)\n",
    "vv, vh = pixel_ts_values[10, :], pixel_ts_values[11, :]\n",
    "# print(f'ndvi:\\n {ndvi}')\n",
    "change_points = np.where(preds[:-1] != preds[1:])[0] + 1\n",
    "cd = dates[np.concatenate([[0], change_points, [-1]])]\n",
    "lcc = preds[np.concatenate([[0], change_points])]\n",
    "\n",
    "events = ['Invasion', 'Mowing 1st', 'Mowing 2nd', 'Waterlogging', 'Herbicide control', 'Recurring', 'WL_fast', 'Restoration','No change']\n",
    "output = extract_change_event_from_pixel(lcc, change_points) if len(lcc) > 1 else np.concatenate([np.repeat(99, len(events) - 1), np.array([preds[0]])])\n",
    "print(f'lcc:\\t {lcc}\\ncd:\\t {change_points}')\n",
    "print(f'output: {output}')\n",
    "print(f'change dates:\\t {[date.strftime('%Y-%m') for date in dates[change_points]]};\\nland cover:\\t {[lc_clrmap[i][1] for i in lcc]};')\n",
    "hped_event = [(event, output[i]) for i, event in enumerate(events) if output[i] != 99]\n",
    "hped_event = sorted(hped_event, key=lambda x: x[1])\n",
    "hped_event = [t[0] for t in hped_event]\n",
    "print(f'happened event:\\t {hped_event}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GradCAM import GradCAM\n",
    "\n",
    "lc_category = 0 # S. alterniflora\n",
    "\n",
    "class SemanticSegmentationTarget:\n",
    "    def __init__(self, category, mask):\n",
    "        self.category = category\n",
    "        self.mask = torch.from_numpy(mask)\n",
    "        if torch.cuda.is_available():\n",
    "            self.mask = self.mask.cuda()\n",
    "\n",
    "    def __call__(self, model_output):\n",
    "        return (model_output[self.category, :] * self.mask).sum()\n",
    "\n",
    "def compute_grad_cam(model, inputs, category, target_layers, size=60):\n",
    "    \"\"\" compute Grad-CAM \"\"\"\n",
    "    preds = model(inputs)\n",
    "    mask = torch.argmax(input=preds, axis=1).detach().cpu().numpy()\n",
    "    mask_float = np.float32(mask == category)\n",
    "\n",
    "    targets = [SemanticSegmentationTarget(category, mask_float)]\n",
    "    with GradCAM(model=model,\n",
    "                target_layers=target_layers) as cam:\n",
    "        gradcam_values = cam(input_tensor=inputs, targets=targets, size=size)[0]\n",
    "    return gradcam_values\n",
    "\n",
    "attn_weights = list()\n",
    "if isinstance(model, TSSCD_TransEncoder):\n",
    "    def hook(module, input, output):\n",
    "        attn_weights.append(output[1])\n",
    "        return None\n",
    "    model.transformer_encoder.layers[-1].self_attn.register_forward_hook(hook)\n",
    "    \n",
    "    target_layer = model.transformer_encoder.norm\n",
    "    cam_norm = compute_grad_cam(model, model_input, int(lc_category), [target_layer])[0]\n",
    "    # attention weights (60, 60) @ global average of the gradients (1, 60)\n",
    "    print(f'attn_weights shape: {attn_weights[-1].squeeze().detach().cpu().numpy().shape}')\n",
    "    grad_cam = np.dot(attn_weights[-1].squeeze().detach().cpu().numpy(), \n",
    "                      cam_norm.transpose(1, 0)).squeeze()\n",
    "else:\n",
    "    if isinstance(model, TSSCD_Unet):\n",
    "        target_layer = model.dec1.conv.net[3]\n",
    "    elif isinstance(model, TSSCD_FCN):\n",
    "        # target_layer = model.layer4[0].net[3] # ?\n",
    "        target_layer = model.layer3[0].net[3] # ?\n",
    "    grad_cam = compute_grad_cam(model, model_input, int(lc_category), [target_layer])[0].squeeze()\n",
    "\n",
    "grad_cam = np.interp(\n",
    "    np.linspace(0, 59, 60 * 3),\n",
    "    np.arange(60),\n",
    "    grad_cam)\n",
    "print(f'cam_norm shape: {grad_cam.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def plot_cls_result(\n",
    "    grad_cam_value=grad_cam,\n",
    "    plot_grad_cam=True,\n",
    "    show_lat_lon=True,\n",
    "    show_event_label=True,\n",
    "    fig_size=(8, 2),\n",
    "    y_lim=(-0.8, 1),\n",
    "    v3h_lim=(-20, 10),\n",
    "\n",
    "):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=fig_size, dpi=300)\n",
    "    ax.set_ylabel('NDVI', fontsize=12, labelpad=5)\n",
    "    ax_v3h = ax.twinx()\n",
    "    ax_v3h.set_ylabel('VV/VH (dB)', fontsize=12, labelpad=5)\n",
    "\n",
    "    # Plot NDVI\n",
    "    for i in range(len(cd) - 1):\n",
    "        idx_start, idx_end = dates.get_loc(cd[i]), dates.get_loc(cd[i + 1]) + 1\n",
    "        color = 'black' if not plot_grad_cam else lc_clrmap[lcc[i]][0]\n",
    "            \n",
    "        ax.scatter(dates[idx_start: idx_end], ndvi[idx_start: idx_end],\n",
    "                c=color, s=8, marker='o',zorder=99, alpha=0.8)    # s=16\n",
    "        idx_start = 1 if idx_start == 0 else idx_start\n",
    "        ax.plot(dates[idx_start - 1: idx_end], ndvi[idx_start - 1: idx_end], \\\n",
    "                c=color, linestyle='-', alpha=1, linewidth=0.7)\n",
    "        \n",
    "    # SAR backscatter\n",
    "    for ts, label, marker in zip(list([vv, vh]), list(['VV', 'VH']), list(['s', '^'])):\n",
    "        ax_v3h.scatter(dates, ts, c='black', s=8, marker=marker, zorder=99, alpha=0.8)\n",
    "        ax_v3h.plot(dates, ts, color='black', linewidth=0.7, alpha=1)\n",
    "    \n",
    "    # Event vline\n",
    "    if show_event_label: \n",
    "        for i, _ in zip(range(0, len(change_points)), hped_event):\n",
    "            ax.axvline(x=dates[change_points[i]] - pd.Timedelta(days=15), \n",
    "                    linestyle='--', alpha=1, zorder=0, linewidth=1.5,\n",
    "                    color=\"#000000\")\n",
    "    if not plot_grad_cam:\n",
    "        cls_bg = np.insert(np.append(change_points, 59), 0, 0)\n",
    "        for i in range(0, len(cls_bg)):\n",
    "            if i < len(cls_bg) - 1:\n",
    "                ax.axvspan(\n",
    "                    xmin=dates[cls_bg[i]] - pd.Timedelta(days=15),\n",
    "                    xmax=dates[cls_bg[i+1]] - pd.Timedelta(days=15) if i < len(cls_bg) - 2 else dates[cls_bg[i+1]] + pd.Timedelta(days=15),\n",
    "                    color=lc_clrmap[lcc[i]][0],\n",
    "                    alpha=0.2 if lc_clrmap[lcc[i]][1] != 'Herbicide-treated litter' else 0.5,\n",
    "                )\n",
    "\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=12))\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator(interval=1))\n",
    "    # ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.6))\n",
    "\n",
    "    # ax.tick_params(axis='x', rotation=30, labelsize=8, length=3, labelbottom=True, which='major')\n",
    "    ax.tick_params(axis='x', labelsize=8, length=3, labelbottom=True, which='major')\n",
    "    ax.tick_params(axis='y', pad=6)\n",
    "\n",
    "    start_date, end_date = pd.Timestamp('2019-12-20'), pd.Timestamp('2024-12-10')\n",
    "    ax.set_xlim(start_date, end_date)\n",
    "\n",
    "    # location: lat, lon\n",
    "    if show_lat_lon:\n",
    "        ax.text(\n",
    "            0.01, 0.05,\n",
    "            f'lat, lon :  {lat_lon[1]:.4f}, {lat_lon[0]:.4f}',\n",
    "            ha='left', va='bottom',\n",
    "            fontsize=10,\n",
    "            fontweight='bold',\n",
    "            transform=ax.transAxes\n",
    "        )\n",
    "\n",
    "    ax.grid(which='major', linestyle='-', linewidth=0.5, color='gray', alpha=0.5)\n",
    "\n",
    "    # ============================== Grad-CAM heatmap ======================================\n",
    "    if plot_grad_cam:\n",
    "        total_days = (end_date - start_date).days\n",
    "        heatmap = grad_cam_value\n",
    "        num_steps = len(heatmap) + 1\n",
    "        \n",
    "        norm = plt.Normalize(heatmap.min(), heatmap.max())\n",
    "        cmap = plt.cm.Reds\n",
    "        norm = plt.Normalize(heatmap.min(), heatmap.max())\n",
    "\n",
    "        for i, cam_val in enumerate(heatmap):\n",
    "            ratio = i / (num_steps - 1)  # normalize to [0,1]\n",
    "            date_pos = start_date + pd.Timedelta(days=ratio * total_days)\n",
    "            \n",
    "            bar_width = total_days / (num_steps * 1)\n",
    "            \n",
    "            x_min = date_pos - pd.Timedelta(days=bar_width/2)\n",
    "            x_max = date_pos + pd.Timedelta(days=bar_width/2)\n",
    "            \n",
    "            color = cmap(norm(cam_val))\n",
    "            \n",
    "            ax.axvspan(xmin=x_min, xmax=x_max, edgecolor='none', facecolor=color, alpha=0.8, zorder=0)\n",
    "    # ===========================================================================================\n",
    "\n",
    "    ax.set_ylim(y_lim[0], y_lim[1])\n",
    "    ax_v3h.set_ylim(v3h_lim[0], v3h_lim[1])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_cls_result(\n",
    "    grad_cam_value=grad_cam,\n",
    "    plot_grad_cam=True,\n",
    "    show_lat_lon=False,\n",
    "    show_event_label=False,\n",
    "    # fig_size=(8, 1.2),\n",
    "    fig_size=(6, 1.2),\n",
    "    y_lim=(-1.2, 1),\n",
    "    v3h_lim=(-30, 20),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 2), dpi=300)\n",
    "ax.set_ylim(-0.2, 1.2)\n",
    "ax.set_ylabel('probabilities distribution', fontsize=12)\n",
    "\n",
    "lgd_elements = list()\n",
    "\n",
    "# SAR backscatter\n",
    "# for ts, clr, label in zip(list([vv, vh]), ['red', 'blue'], ['VV', 'VH']):\n",
    "#     ax.scatter(dates, ts, c=clr, s=12, marker='o',zorder=99)\n",
    "#     ax.plot(dates, ts, color=clr, linewidth=1.5)\n",
    "#     lgd_elements.append(\n",
    "#         Line2D([0], [0], color=clr[0], marker='s', linestyle='-', markersize=5, linewidth=1.5, label=label)\n",
    "#     )\n",
    "\n",
    "# Output probability\n",
    "for class_prob, clr in zip(class_probs, lc_clrmap.values()):\n",
    "    ax.plot(dates, class_prob, color=clr[0], linewidth=1.5)\n",
    "    ax.scatter(dates, class_prob, c=clr[0], s=12, marker='o', zorder=99)\n",
    "    lgd_elements.append(\n",
    "        Line2D([0], [0], color=clr[0], marker='s', linestyle='-', markersize=5, linewidth=1.5, label=clr[1])\n",
    "    )\n",
    "\n",
    "ax.legend(\n",
    "    handles=lgd_elements,\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(1, 1.2),\n",
    "    ncol=8,\n",
    "    frameon=False,\n",
    "    columnspacing=0.5\n",
    ")\n",
    "    \n",
    "ax.set_xlabel('time step', fontsize=10)\n",
    "ax.set_ylabel('CAM value', fontsize=10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.art3d import PolyCollection\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 12\n",
    "\n",
    "dates_num = mdates.date2num(dates)\n",
    "M, N = model_input_4_plot.shape\n",
    "\n",
    "def scale_3vh(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min()) * 2000\n",
    "\n",
    "model_input_4_plot[-1] = scale_3vh(model_input_4_plot[-1])\n",
    "model_input_4_plot[-2] = scale_3vh(model_input_4_plot[-2])\n",
    "\n",
    "OFFSET = (model_input_4_plot.max() - model_input_4_plot.min()) * 0.2\n",
    "y_offsets = np.arange(M) * OFFSET\n",
    "\n",
    "verts = list()\n",
    "for i in range(M):\n",
    "    xs, ys = dates_num, model_input_4_plot[i]\n",
    "    if i > M - 3:\n",
    "        ys = model_input_4_plot[i] + 1000\n",
    "    top, bottom = list(zip(xs, ys)), list(zip(xs[::-1], np.zeros_like(ys)))\n",
    "    verts.append(top + bottom)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 14), dpi=300)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.set_box_aspect((4, 8, 2))\n",
    "\n",
    "colors = cm.viridis(np.linspace(0, 1, M))\n",
    "poly = PolyCollection(verts, facecolors=colors, alpha=0.8)\n",
    "ax.add_collection3d(poly, zs=y_offsets, zdir='y')\n",
    "\n",
    "\n",
    "# ax Lim\n",
    "ax.set_xlim(dates_num.min(), dates_num.max())\n",
    "ax.set_ylim(y_offsets.min(), y_offsets.max() + OFFSET)\n",
    "ax.set_zlim(model_input_4_plot.min(), model_input_4_plot.max())\n",
    "\n",
    "# ax label setting \n",
    "ax.set_yticks(y_offsets)\n",
    "ax.set_yticklabels(bands_label, rotation=0, va='center')\n",
    "ax.tick_params(axis='y', which='major', pad=10)\n",
    "\n",
    "ax.set_zticks([])\n",
    "ax.set_zticklabels([])\n",
    "\n",
    "ax.zaxis.set_ticks_position('lower')\n",
    "ax.zaxis.set_label_position('lower')\n",
    "\n",
    "ax.tick_params(axis='x', which='major', pad=0, rotation=15)\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "\n",
    "# ax.view_init(elev=20, azim=-60, vertical_axis='z')\n",
    "ax.view_init(elev=20, azim=-60, vertical_axis='z')\n",
    "ax.grid(False)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
